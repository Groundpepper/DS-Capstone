{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b5a97-a196-4d8b-be0d-f409ed90c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deweydatapy@git+https://github.com/Dewey-Data/deweydatapy\n",
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6071d0f4-93d2-418e-a3be-d9ff7ea03b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deweydatapy as ddp\n",
    "\n",
    "APIKEY = \"akv1_QM2Gd4s-bAm-PHHkatlokaVxNzkMISAUXcy\"\n",
    "\n",
    "PPS = {\n",
    "    'person': \"https://api.deweydata.io/api/v1/external/data/fldr_t8vhuaw774eoa4tbj\", #782M\n",
    "    'certification': \"https://api.deweydata.io/api/v1/external/data/fldr_dhhd387qjix63dp6g\", #277M \n",
    "    'degree': \"https://api.deweydata.io/api/v1/external/data/fldr_zpjayejai7zf9m7hv\", #416M\n",
    "    'education': \"https://api.deweydata.io/api/v1/external/data/fldr_yooaittih4rk7hccp\", #672M \n",
    "    'experience': \"https://api.deweydata.io/api/v1/external/data/fldr_rby46swjrtdkg9z8u\", #1.6B \n",
    "    'experience_level': \"https://api.deweydata.io/api/v1/external/data/fldr_exphf7msjs7z76qof\", #420M \n",
    "    'interest': \"https://api.deweydata.io/api/v1/external/data/fldr_yrcjzcttuxjyduvhh\", #308M\n",
    "    'job_level': \"https://api.deweydata.io/api/v1/external/data/fldr_bnux8heehjga7bec8\", #132M\n",
    "    'major': \"https://api.deweydata.io/api/v1/external/data/fldr_mia6kqyahgcxhqbxi\", #492M\n",
    "    'minor': \"https://api.deweydata.io/api/v1/external/data/fldr_xkbx8rpk8pn7vccjn\", #2.1M\n",
    "    'skill': \"https://api.deweydata.io/api/v1/external/data/fldr_rcnddwegyg7aa7r77\" #2.4B \n",
    "}\n",
    "\n",
    "RELEVANT_COLUMNS = {\n",
    "    'person': ['BIRTH_YEAR', 'INDUSTRY', 'JOB_COMPANY_INDUSTRY', 'JOB_LAST_CHANGED', 'JOB_START_DATE',\n",
    "               'JOB_TITLE', 'JOB_TITLE_CLASS', 'JOB_TITLE_ROLE', 'JOB_TITLE_SUB_ROLE', 'PERSON_ID', 'SEX'],\n",
    "    'certification': ['NAME', 'PERSON_ID', 'ORGANIZATION', 'START_DATE', 'END_DATE'],\n",
    "    'degree': ['EDUCATION_ID', 'DEGREE'], # DONE\n",
    "    'education': ['ID', 'SCHOOL_TYPE', 'GPA', 'START_DATE', 'SCHOOL_NAME', 'END_DATE', 'PERSON_ID'],\n",
    "    'experience': ['ID', 'COMPANY_NAME', 'END_DATE', 'TITLE_SUB_ROLE', 'TITLE_NAME', 'START_DATE',\n",
    "                  'COMPANY_INDUSTRY', 'TITLE_ROLE', 'PERSON_ID'],\n",
    "    'experience_level': ['EXPERIENCE_ID', 'LEVEL'], # DONE\n",
    "    'interest': ['PERSON_ID', 'INTEREST'],\n",
    "    'job_level': ['PERSON_ID', 'LEVEL'], # DONE\n",
    "    'major': ['EDUCATION_ID', 'MAJOR'], # DONE\n",
    "    'minor': ['EDUCATION_ID', 'MINOR'], # DONE\n",
    "    'skill': ['PERSON_ID', 'SKILL'] # DONE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed279bb6-292d-4f0b-820f-471c992df797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x14fb2de48970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62d0418-e73f-4ba5-83c3-b13b86d6d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/10...\n",
      "Collecting files information for page 2/10...\n",
      "Collecting files information for page 3/10...\n",
      "Collecting files information for page 4/10...\n",
      "Collecting files information for page 5/10...\n",
      "Collecting files information for page 6/10...\n",
      "Collecting files information for page 7/10...\n",
      "Collecting files information for page 8/10...\n",
      "Collecting files information for page 9/10...\n",
      "Collecting files information for page 10/10...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 10\n",
      "Total number of files: 466\n",
      "Total files size (MB): 100,305.29\n",
      "Average single file size (MB): 215.07\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:04.374114+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/4...\n",
      "Collecting files information for page 2/4...\n",
      "Collecting files information for page 3/4...\n",
      "Collecting files information for page 4/4...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 4\n",
      "Total number of files: 191\n",
      "Total files size (MB): 7,071.42\n",
      "Average single file size (MB): 37.0\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:08.160659+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/2...\n",
      "Collecting files information for page 2/2...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 2\n",
      "Total number of files: 68\n",
      "Total files size (MB): 1,846.17\n",
      "Average single file size (MB): 26.96\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:10.729219+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/18...\n",
      "Collecting files information for page 2/18...\n",
      "Collecting files information for page 3/18...\n",
      "Collecting files information for page 4/18...\n",
      "Collecting files information for page 5/18...\n",
      "Collecting files information for page 6/18...\n",
      "Collecting files information for page 7/18...\n",
      "Collecting files information for page 8/18...\n",
      "Collecting files information for page 9/18...\n",
      "Collecting files information for page 10/18...\n",
      "Collecting files information for page 11/18...\n",
      "Collecting files information for page 12/18...\n",
      "Collecting files information for page 13/18...\n",
      "Collecting files information for page 14/18...\n",
      "Collecting files information for page 15/18...\n",
      "Collecting files information for page 16/18...\n",
      "Collecting files information for page 17/18...\n",
      "Collecting files information for page 18/18...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 18\n",
      "Total number of files: 888\n",
      "Total files size (MB): 44,879.34\n",
      "Average single file size (MB): 50.55\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:11.915015+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/59...\n",
      "Collecting files information for page 2/59...\n",
      "Collecting files information for page 3/59...\n",
      "Collecting files information for page 4/59...\n",
      "Collecting files information for page 5/59...\n",
      "Collecting files information for page 6/59...\n",
      "Collecting files information for page 7/59...\n",
      "Collecting files information for page 8/59...\n",
      "Collecting files information for page 9/59...\n",
      "Collecting files information for page 10/59...\n",
      "Collecting files information for page 11/59...\n",
      "Collecting files information for page 12/59...\n",
      "Collecting files information for page 13/59...\n",
      "Collecting files information for page 14/59...\n",
      "Collecting files information for page 15/59...\n",
      "Collecting files information for page 16/59...\n",
      "Collecting files information for page 17/59...\n",
      "Collecting files information for page 18/59...\n",
      "Collecting files information for page 19/59...\n",
      "Collecting files information for page 20/59...\n",
      "Collecting files information for page 21/59...\n",
      "Collecting files information for page 22/59...\n",
      "Collecting files information for page 23/59...\n",
      "Collecting files information for page 24/59...\n",
      "Collecting files information for page 25/59...\n",
      "Collecting files information for page 26/59...\n",
      "Collecting files information for page 27/59...\n",
      "Collecting files information for page 28/59...\n",
      "Collecting files information for page 29/59...\n",
      "Collecting files information for page 30/59...\n",
      "Collecting files information for page 31/59...\n",
      "Collecting files information for page 32/59...\n",
      "Collecting files information for page 33/59...\n",
      "Collecting files information for page 34/59...\n",
      "Collecting files information for page 35/59...\n",
      "Collecting files information for page 36/59...\n",
      "Collecting files information for page 37/59...\n",
      "Collecting files information for page 38/59...\n",
      "Collecting files information for page 39/59...\n",
      "Collecting files information for page 40/59...\n",
      "Collecting files information for page 41/59...\n",
      "Collecting files information for page 42/59...\n",
      "Collecting files information for page 43/59...\n",
      "Collecting files information for page 44/59...\n",
      "Collecting files information for page 45/59...\n",
      "Collecting files information for page 46/59...\n",
      "Collecting files information for page 47/59...\n",
      "Collecting files information for page 48/59...\n",
      "Collecting files information for page 49/59...\n",
      "Collecting files information for page 50/59...\n",
      "Collecting files information for page 51/59...\n",
      "Collecting files information for page 52/59...\n",
      "Collecting files information for page 53/59...\n",
      "Collecting files information for page 54/59...\n",
      "Collecting files information for page 55/59...\n",
      "Collecting files information for page 56/59...\n",
      "Collecting files information for page 57/59...\n",
      "Collecting files information for page 58/59...\n",
      "Collecting files information for page 59/59...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 59\n",
      "Total number of files: 2,905\n",
      "Total files size (MB): 150,644.48\n",
      "Average single file size (MB): 51.87\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:19.229596+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/2...\n",
      "Collecting files information for page 2/2...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 2\n",
      "Total number of files: 65\n",
      "Total files size (MB): 2,000.35\n",
      "Average single file size (MB): 31.38\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:41.352155+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/2...\n",
      "Collecting files information for page 2/2...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 2\n",
      "Total number of files: 67\n",
      "Total files size (MB): 2,537.05\n",
      "Average single file size (MB): 38.34\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:42.523059+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/2...\n",
      "Collecting files information for page 2/2...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 2\n",
      "Total number of files: 67\n",
      "Total files size (MB): 2,213.46\n",
      "Average single file size (MB): 33.16\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:43.804201+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/2...\n",
      "Collecting files information for page 2/2...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 2\n",
      "Total number of files: 82\n",
      "Total files size (MB): 2,793.06\n",
      "Average single file size (MB): 33.8\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:44.755041+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 8\n",
      "Total files size (MB): 14.29\n",
      "Average single file size (MB): 1.79\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:45.728709+00:00\n",
      "-----------------------------------------------------------------\n",
      "Collecting files information for page 1/8...\n",
      "Collecting files information for page 2/8...\n",
      "Collecting files information for page 3/8...\n",
      "Collecting files information for page 4/8...\n",
      "Collecting files information for page 5/8...\n",
      "Collecting files information for page 6/8...\n",
      "Collecting files information for page 7/8...\n",
      "Collecting files information for page 8/8...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 8\n",
      "Total number of files: 371\n",
      "Total files size (MB): 17,543.48\n",
      "Average single file size (MB): 47.27\n",
      "Date partition column: None\n",
      "Expires at: 2025-10-16T06:11:46.314470+00:00\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "person_urls = ddp.get_file_list(APIKEY, PPS['person']).link.to_list()\n",
    "certification_urls = ddp.get_file_list(APIKEY, PPS['certification']).link.to_list()\n",
    "degree_urls = ddp.get_file_list(APIKEY, PPS['degree']).link.to_list()\n",
    "education_urls = ddp.get_file_list(APIKEY, PPS['education']).link.to_list()\n",
    "experience_urls = ddp.get_file_list(APIKEY, PPS['experience']).link.to_list()\n",
    "experience_level_urls = ddp.get_file_list(APIKEY, PPS['experience_level']).link.to_list()\n",
    "interest_urls = ddp.get_file_list(APIKEY, PPS['interest']).link.to_list()\n",
    "job_level_urls = ddp.get_file_list(APIKEY, PPS['job_level']).link.to_list()\n",
    "major_urls = ddp.get_file_list(APIKEY, PPS['major']).link.to_list()\n",
    "minor_urls = ddp.get_file_list(APIKEY, PPS['minor']).link.to_list()\n",
    "skill_urls = ddp.get_file_list(APIKEY, PPS['skill']).link.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59cfdd-c9ed-4b18-96c2-cb663be53417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dewey_data_urls = [\n",
    "    person_urls, certification_urls, degree_urls, education_urls, experience_urls,\n",
    "    experience_level_urls, interest_urls, job_level_urls, major_urls, minor_urls, skill_urls\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5261d8-7758-465f-a4b9-db110a3dc16d",
   "metadata": {},
   "source": [
    "Download all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d65d5c-f96c-4333-90a8-cf8863ecbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for url, dataset_name in zip(dewey_data_urls, RELEVANT_COLUMNS.keys()):\n",
    "    columns = RELEVANT_COLUMNS[dataset_name]\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    con.execute(f\"\"\"\n",
    "        SET temp_directory = 'tmp';\n",
    "        SET preserve_insertion_order = false;\n",
    "        SET memory_limit='120GB';\n",
    "\n",
    "        COPY (\n",
    "            SELECT\n",
    "                {', '.join(columns)}\n",
    "            FROM read_csv({url}, compression='gzip')\n",
    "        ) TO 'dewey_data/{dataset_name}.parquet' (\n",
    "            FORMAT PARQUET\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    print(f'Finished {dataset_name} in {(time.time() - start) / 60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95cc87-00b3-4431-a553-456b439d7ee2",
   "metadata": {},
   "source": [
    "Join lower level datasets into higher level datasets as \"MERGED\" datasets\n",
    "\n",
    "This must be done for\n",
    "* experience_level -> experience\n",
    "* major, minor, degree -> education\n",
    "* job_level, skill, certification -> person [not needed atm, to be merged at the end]\n",
    "\n",
    "NOTE: incidentally some of the code for generating these datasets are missing\n",
    "* experience_merged is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85139dd7-7298-47e3-9124-9db6126e4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    SET temp_directory = 'tmp';\n",
    "    SET preserve_insertion_order = false;\n",
    "    SET memory_limit='120GB';\n",
    "    \n",
    "    COPY (\n",
    "        SELECT\n",
    "            e.PERSON_ID AS PERSON_ID,\n",
    "            e.SCHOOL_TYPE AS SCHOOL_TYPE,\n",
    "            e.GPA AS GPA,\n",
    "            e.START_DATE AS EDUCATION_START_DATE,\n",
    "            e.SCHOOL_NAME AS SCHOOL_NAME,\n",
    "            e.END_DATE AS EDUCATION_END_DATE,\n",
    "            d.DEGREE AS DEGREE,\n",
    "            ma.MAJOR AS MAJOR,\n",
    "            mi.MINOR AS MINOR\n",
    "        FROM 'dewey_data/education.parquet' e\n",
    "            LEFT JOIN 'dewey_processed/degree.parquet' d ON e.ID = d.EDUCATION_ID\n",
    "            LEFT JOIN 'dewey_processed/major.parquet' ma ON e.ID = ma.EDUCATION_ID\n",
    "            LEFT JOIN 'dewey_processed/minor.parquet' mi ON e.ID = mi.EDUCATION_ID\n",
    "    )\n",
    "    TO 'dewey_merged/education_merged.parquet' (\n",
    "        FORMAT PARQUET\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "print((time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76b108-a589-47c4-aef7-dbb66d8a3a30",
   "metadata": {},
   "source": [
    "education_merged and experience_merged must then be processed to join by person_id with the person dataset\n",
    "\n",
    "This means that, in the scenario that a person has multiple education and/or experiences, the dataset must be reorganized by person_id\n",
    "* ie., for education_merged_processed: person_id, [degree_1, degree_2], [major_1, major_2], ...(other education columns)\n",
    "* same for experience\n",
    "\n",
    "NOTE: incidentally code for generating education_merged_processed and experience_merged_processed are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374c403-668d-46fe-a696-93b60a2f9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00085899-8c67-42ff-9c48-d95dcc1238bf",
   "metadata": {},
   "source": [
    "Merging everything into a single dataset\n",
    "* a for-loop is required as loading all datasets takes too much memory; done in iterations by id instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63490bab-9878-4c43-9226-afe3a00044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, os, time\n",
    "\n",
    "os.makedirs(\"test\", exist_ok=True)\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    SET temp_directory = 'tmp';\n",
    "    SET preserve_insertion_order = false;\n",
    "    SET memory_limit = '120GB';\n",
    "\"\"\")\n",
    "\n",
    "start = time.time()\n",
    "NUM_BUCKETS = 20\n",
    "\n",
    "for i in range(NUM_BUCKETS):\n",
    "    print(f\"Processing bucket {i+1}/{NUM_BUCKETS}...\")\n",
    "    con.execute(f\"\"\"\n",
    "        COPY (\n",
    "            SELECT\n",
    "                p.PERSON_ID AS PERSON_ID,\n",
    "                p.BIRTH_YEAR AS BIRTH_YEAR,\n",
    "                p.INDUSTRY AS INDUSTRY,\n",
    "                p.JOB_COMPANY_INDUSTRY AS JOB_COMPANY_INDUSTRY,\n",
    "                p.JOB_LAST_CHANGED AS JOB_LAST_CHANGED,\n",
    "                p.JOB_START_DATE AS JOB_START_DATE,\n",
    "                p.JOB_TITLE AS JOB_TITLE,\n",
    "                p.JOB_TITLE_CLASS AS JOB_TITLE_CLASS,\n",
    "                p.JOB_TITLE_ROLE AS JOB_TITLE_ROLE,\n",
    "                p.JOB_TITLE_SUB_ROLE AS JOB_TITLE_SUB_ROLE,\n",
    "                p.SEX AS SEX,\n",
    "                jl.LEVEL AS JOB_LEVEL,\n",
    "                i.INTEREST AS INTEREST,\n",
    "                s.SKILL AS SKILL,\n",
    "                c.NAME AS CERTIFICATION_NAME,\n",
    "                c.ORGANIZATION AS CERTIFICATION_ORGANIZATION,\n",
    "                c.START_DATE AS CERTIFICATION_START_DATE,\n",
    "                c.END_DATE AS CERTIFICATION_END_DATE,\n",
    "                edu.SCHOOL_TYPE AS SCHOOL_TYPE,\n",
    "                edu.GPA AS GPA,\n",
    "                edu.EDUCATION_START_DATE AS EDUCATION_START_DATE,\n",
    "                edu.SCHOOL_NAME AS SCHOOL_NAME,\n",
    "                edu.EDUCATION_END_DATE AS EDUCATION_END_DATE,\n",
    "                edu.DEGREE AS DEGREE,\n",
    "                edu.MAJOR AS MAJOR,\n",
    "                edu.MINOR AS MINOR,\n",
    "                exp.EXPERIENCE_COMPANY_NAME AS EXPERIENCE_COMPANY_NAME,\n",
    "                exp.EXPERIENCE_END_DATE AS EXPERIENCE_END_DATE,\n",
    "                exp.EXPERIENCE_TITLE_SUB_ROLE AS EXPERIENCE_TITLE_SUB_ROLE,\n",
    "                exp.EXPERIENCE_TITLE_NAME AS EXPERIENCE_TITLE_NAME,\n",
    "                exp.EXPERIENCE_START_DATE AS EXPERIENCE_START_DATE,\n",
    "                exp.EXPERIENCE_COMPANY_INDUSTRY AS EXPERIENCE_COMPANY_INDUSTRY,\n",
    "                exp.EXPERIENCE_TITLE_ROLE AS EXPERIENCE_TITLE_ROLE,\n",
    "                exp.EXPERIENCE_LEVEL AS EXPERIENCE_LEVEL\n",
    "            FROM 'dewey_data/person_us.parquet' p\n",
    "                LEFT JOIN 'dewey_processed/certification.parquet' c \n",
    "                    ON p.PERSON_ID = c.PERSON_ID\n",
    "                LEFT JOIN 'dewey_processed/job_level.parquet' jl \n",
    "                    ON p.PERSON_ID = jl.PERSON_ID\n",
    "                LEFT JOIN 'dewey_processed/interest.parquet' i \n",
    "                    ON p.PERSON_ID = i.PERSON_ID\n",
    "                LEFT JOIN 'dewey_processed/skill.parquet' s \n",
    "                    ON p.PERSON_ID = s.PERSON_ID\n",
    "                LEFT JOIN 'dewey_merged/experience_merged_processed.parquet' exp \n",
    "                    ON p.PERSON_ID = exp.PERSON_ID\n",
    "                LEFT JOIN 'dewey_merged/education_merged_processed.parquet' edu \n",
    "                    ON p.PERSON_ID = edu.PERSON_ID\n",
    "            WHERE MOD(HASH(p.PERSON_ID), {NUM_BUCKETS}) = {i}\n",
    "        )\n",
    "        TO 'test/final_bucket_us_{i}.parquet' (FORMAT PARQUET);\n",
    "    \"\"\")\n",
    "\n",
    "print(\"Merging all partial buckets...\")\n",
    "con.execute(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_parquet('test/final_bucket_us_*.parquet')\n",
    "    )\n",
    "    TO 'dewey_final/final_us.parquet' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Finished in {(time.time()-start)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5c4b8-cc03-4869-a465-3875d08c17e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
